{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark initialized.\n"
     ]
    }
   ],
   "source": [
    "# import necessary library\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType\n",
    "\n",
    "# entry point for spark's functionality\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "\n",
    "# configure = SparkConf().setAppName(\"Test\").setMaster(\"local\")\n",
    "# sc = SparkContext(conf= configure)\n",
    "# sql = SQLContext(sc)\n",
    "\n",
    "# entry point for spark's dataframes\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Test\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.crealytics:spark-excel_2.11:0.12.2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"spark initialized.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "excel_path = \"D:/workspace/digipay-data-science/dp-marketing/csv/2-4_azar_bnpl.xlsx\"\n",
    "sheet_name = \"Sheet1\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\app\\python38\\lib\\site-packages\\pyspark\\pandas\\namespace.py:1078: FutureWarning: convert_float is deprecated and will be removed in a future version\n",
      "  return pd.read_excel(\n"
     ]
    },
    {
     "ename": "ArrowTypeError",
     "evalue": "Expected bytes, got a 'int' object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mArrowTypeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20964\\1947584390.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# bnpl_encode_csv = pyspark.pandas.read_excel(\"csv/2-4_azar_bnpl.xlsx\")\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m bnpl_encode_csv = pyspark.pandas.read_excel(\"D:/workspace/digipay-data-science/dp-marketing/csv/2-4_azar_bnpl.xlsx\"\n\u001B[0m\u001B[0;32m      3\u001B[0m         , index_col=None, header=None, dtype={'CustomerID': str, 'mobile hash':str,'FirstName':str,'LastName':str} )\n\u001B[0;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbnpl_encode_csv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\python38\\lib\\site-packages\\pyspark\\pandas\\namespace.py\u001B[0m in \u001B[0;36mread_excel\u001B[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001B[0m\n\u001B[0;32m   1121\u001B[0m             )\n\u001B[0;32m   1122\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1123\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mUnion\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mSeries\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_pandas\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpdf_or_psers\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1124\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1125\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\python38\\lib\\site-packages\\pyspark\\pandas\\namespace.py\u001B[0m in \u001B[0;36mfrom_pandas\u001B[1;34m(pobj)\u001B[0m\n\u001B[0;32m    141\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mSeries\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    142\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 143\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    144\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIndex\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    145\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\python38\\lib\\site-packages\\pyspark\\pandas\\frame.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[0;32m    518\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    519\u001B[0m                 \u001B[0mpdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 520\u001B[1;33m             \u001B[0minternal\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mInternalFrame\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_pandas\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpdf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    521\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    522\u001B[0m         \u001B[0mobject\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__setattr__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"_internal_frame\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minternal\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\python38\\lib\\site-packages\\pyspark\\pandas\\internal.py\u001B[0m in \u001B[0;36mfrom_pandas\u001B[1;34m(pdf)\u001B[0m\n\u001B[0;32m   1458\u001B[0m             \u001B[0mdata_columns\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1459\u001B[0m             \u001B[0mdata_fields\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1460\u001B[1;33m         ) = InternalFrame.prepare_pandas_frame(pdf)\n\u001B[0m\u001B[0;32m   1461\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1462\u001B[0m         \u001B[0mschema\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mStructType\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mfield\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstruct_field\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mfield\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mindex_fields\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mdata_fields\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\python38\\lib\\site-packages\\pyspark\\pandas\\internal.py\u001B[0m in \u001B[0;36mprepare_pandas_frame\u001B[1;34m(pdf, retain_index)\u001B[0m\n\u001B[0;32m   1531\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1532\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mcol\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreset_index\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreset_index\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtypes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1533\u001B[1;33m             \u001B[0mspark_type\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minfer_pd_series_spark_type\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreset_index\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcol\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1534\u001B[0m             \u001B[0mreset_index\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcol\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mDataTypeOps\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mspark_type\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprepare\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreset_index\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcol\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1535\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\python38\\lib\\site-packages\\pyspark\\pandas\\typedef\\typehints.py\u001B[0m in \u001B[0;36minfer_pd_series_spark_type\u001B[1;34m(pser, dtype)\u001B[0m\n\u001B[0;32m    327\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mpser\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__UDT__\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    328\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 329\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfrom_arrow_type\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpa\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mArray\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_pandas\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpser\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    330\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mCategoricalDtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    331\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpser\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mCategoricalDtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\python38\\lib\\site-packages\\pyarrow\\array.pxi\u001B[0m in \u001B[0;36mpyarrow.lib.Array.from_pandas\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mD:\\app\\python38\\lib\\site-packages\\pyarrow\\array.pxi\u001B[0m in \u001B[0;36mpyarrow.lib.array\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mD:\\app\\python38\\lib\\site-packages\\pyarrow\\array.pxi\u001B[0m in \u001B[0;36mpyarrow.lib._ndarray_to_array\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mD:\\app\\python38\\lib\\site-packages\\pyarrow\\error.pxi\u001B[0m in \u001B[0;36mpyarrow.lib.check_status\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mArrowTypeError\u001B[0m: Expected bytes, got a 'int' object"
     ]
    }
   ],
   "source": [
    "# bnpl_encode_csv = pyspark.pandas.read_excel(\"csv/2-4_azar_bnpl.xlsx\")\n",
    "bnpl_encode_csv = pyspark.pandas.read_excel(excel_path\n",
    "        , index_col=None, header=None, dtype={'CustomerID':str,'mobile hash':str,'FirstName':str,'LastName':str} )\n",
    "print(bnpl_encode_csv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o93.load.\n: java.lang.ClassNotFoundException: \nFailed to find data source: com.crealytics.spark.excel. Please find packages at\nhttp://spark.apache.org/third-party-projects.html\n       \r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.failedToFindDataSourceError(QueryExecutionErrors.scala:443)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:670)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:720)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:210)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ClassNotFoundException: com.crealytics.spark.excel.DefaultSource\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:382)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:656)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:656)\r\n\tat scala.util.Failure.orElse(Try.scala:224)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:656)\r\n\t... 15 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20964\\1617705982.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0msdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mspark\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"com.crealytics.spark.excel\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0moption\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"location\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"D:/workspace/digipay-data-science/dp-marketing/csv/2-4_azar_bnpl.xlsx\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0moption\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"useHeader\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"true\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0moption\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"treatEmptyValuesAsNulls\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"true\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\python38\\lib\\site-packages\\pyspark\\sql\\readwriter.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(self, path, format, schema, **options)\u001B[0m\n\u001B[0;32m    162\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_df\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jreader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_spark\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jvm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mPythonUtils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtoSeq\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    163\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 164\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_df\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jreader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    165\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    166\u001B[0m     def json(self, path, schema=None, primitivesAsString=None, prefersDecimal=None,\n",
      "\u001B[1;32mD:\\app\\python38\\lib\\site-packages\\py4j\\java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m   1319\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1320\u001B[0m         \u001B[0manswer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1321\u001B[1;33m         return_value = get_return_value(\n\u001B[0m\u001B[0;32m   1322\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[0;32m   1323\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\python38\\lib\\site-packages\\pyspark\\sql\\utils.py\u001B[0m in \u001B[0;36mdeco\u001B[1;34m(*a, **kw)\u001B[0m\n\u001B[0;32m    109\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    110\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 111\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    112\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    113\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\python38\\lib\\site-packages\\py4j\\protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[1;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[0;32m    324\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mOUTPUT_CONVERTER\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    325\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 326\u001B[1;33m                 raise Py4JJavaError(\n\u001B[0m\u001B[0;32m    327\u001B[0m                     \u001B[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n",
      "\u001B[1;31mPy4JJavaError\u001B[0m: An error occurred while calling o93.load.\n: java.lang.ClassNotFoundException: \nFailed to find data source: com.crealytics.spark.excel. Please find packages at\nhttp://spark.apache.org/third-party-projects.html\n       \r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.failedToFindDataSourceError(QueryExecutionErrors.scala:443)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:670)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:720)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:210)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ClassNotFoundException: com.crealytics.spark.excel.DefaultSource\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:382)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:656)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:656)\r\n\tat scala.util.Failure.orElse(Try.scala:224)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:656)\r\n\t... 15 more\r\n"
     ]
    }
   ],
   "source": [
    "sdf = spark.read \\\n",
    ".format(\"com.crealytics.spark.excel\") \\\n",
    ".option(\"location\", excel_path) \\\n",
    ".option(\"useHeader\", \"true\") \\\n",
    ".option(\"treatEmptyValuesAsNulls\", \"true\") \\\n",
    ".option(\"inferSchema\", \"true\") \\\n",
    ".option(\"addColorColumns\", \"False\") \\\n",
    ".load()\n",
    "print(sdf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o156.load.\n: java.lang.ClassNotFoundException: \nFailed to find data source: com.crealytics.spark.excel. Please find packages at\nhttp://spark.apache.org/third-party-projects.html\n       \r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.failedToFindDataSourceError(QueryExecutionErrors.scala:443)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:670)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:720)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:210)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:188)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ClassNotFoundException: com.crealytics.spark.excel.DefaultSource\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:382)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:656)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:656)\r\n\tat scala.util.Failure.orElse(Try.scala:224)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:656)\r\n\t... 15 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20964\\4119488022.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# reading excel file\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mdf_generika\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mspark\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"com.crealytics.spark.excel\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moption\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"useHeader\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"true\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moption\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"inferSchema\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"true\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m     \u001B[1;33m.\u001B[0m\u001B[0moption\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"dataAddress\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msheet_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mexcel_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf_generika\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\python38\\lib\\site-packages\\pyspark\\sql\\readwriter.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(self, path, format, schema, **options)\u001B[0m\n\u001B[0;32m    156\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    157\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 158\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_df\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jreader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    159\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mpath\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    160\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\python38\\lib\\site-packages\\py4j\\java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m   1319\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1320\u001B[0m         \u001B[0manswer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1321\u001B[1;33m         return_value = get_return_value(\n\u001B[0m\u001B[0;32m   1322\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[0;32m   1323\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\python38\\lib\\site-packages\\pyspark\\sql\\utils.py\u001B[0m in \u001B[0;36mdeco\u001B[1;34m(*a, **kw)\u001B[0m\n\u001B[0;32m    109\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    110\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 111\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    112\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    113\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\python38\\lib\\site-packages\\py4j\\protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[1;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[0;32m    324\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mOUTPUT_CONVERTER\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    325\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 326\u001B[1;33m                 raise Py4JJavaError(\n\u001B[0m\u001B[0;32m    327\u001B[0m                     \u001B[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n",
      "\u001B[1;31mPy4JJavaError\u001B[0m: An error occurred while calling o156.load.\n: java.lang.ClassNotFoundException: \nFailed to find data source: com.crealytics.spark.excel. Please find packages at\nhttp://spark.apache.org/third-party-projects.html\n       \r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.failedToFindDataSourceError(QueryExecutionErrors.scala:443)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:670)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:720)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:210)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:188)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ClassNotFoundException: com.crealytics.spark.excel.DefaultSource\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:382)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:656)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:656)\r\n\tat scala.util.Failure.orElse(Try.scala:224)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:656)\r\n\t... 15 more\r\n"
     ]
    }
   ],
   "source": [
    "# reading excel file\n",
    "df_generika = spark.read.format(\"com.crealytics.spark.excel\").option(\"useHeader\", \"true\").option(\"inferSchema\", \"true\")\\\n",
    "    .option(\"dataAddress\", sheet_name).load(excel_path)\n",
    "print(df_generika)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}